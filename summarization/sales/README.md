# Sales Call Summarization

This app is designed to demonstrate a tool for summarizing sales calls transcriptions using three techniques for summarization with Large Language Models (LLMs): Stuff, Map-Reduce, and Refine.

### Stuff

The "Stuff" technique in the context of LLMs involves "feeding" the model with a large amount of information or "stuffing" it with data, and then prompting it to generate a summary based on the provided information. This is the simplest approach and have some limitations such as the risk of information overload. When too much information is fed into the model, it can struggle to identify and prioritize the most relevant and important points for the summary.

### Map-Reduce

The Map-Reduce technique is inspired by the MapReduce programming model. Applied to LLMs for summarization, this technique involves two steps: "Map", where the text is divided into smaller segments/chunks, and each segment is summarized independently, followed by "Reduce", where these individual summaries are combined into a final summary. This approach is particularly useful for summarizing very long documents or collections of documents, as it allows the model to handle the task in a scalable and efficient manner.

### Refine

The "Refine" technique focuses on iteratively improving the quality of a summary. Initially, a preliminary summary is generated by the LLM. This summary is then fed back into the model, along with the original text, with instructions to refine or improve the summary based on certain criteria, such as clarity, conciseness, or the inclusion of key points. This process can be repeated multiple times, with each iteration aimed at enhancing the accuracy and quality of the summary. The Refine technique leverages the model's ability to evaluate and edit its own output, making it a powerful tool for producing high-quality summaries.

## How to Run

**Step 1: Configure OpenAI API Key**

   1. Locate the file named docker-compose.yml in the current directory. This file contains configurations for running the demo using Docker.
   2. Open the docker-compose.yml file using a text editor.
   3. Replace the placeholder <YOUR OPENAI_API_KEY> with your actual OpenAI API Key. 
   4. Save the changes you made to the docker-compose.yml file.


**Step 2: Running the Application**

   With the OpenAI API key configured, you can now run the application. Open a terminal, navigate to the project directory, and run:

   ```
   docker-compose up
   ```

   This command builds the Docker image (if it's the first time running it) and starts the application. Wait for the process to complete, and the application should be up and running.

   Once the services are up and running, open your web browser and navigate to http://localhost:8502. This will launch the product search demo application.

### Sample Data

We provide a fictitious sales call transcription in `summarization/sales/sample_data` directory to be used as example in the app.

## Acknowledgments

This project utilizes OpenAI's GPT-4-turbo model for generating summaries.

## Limitations

Please note that this is a demonstration intended for testing purposes only. If you require this use case with additional requirements or in a production environment, please contact us at contato@reppie.io .